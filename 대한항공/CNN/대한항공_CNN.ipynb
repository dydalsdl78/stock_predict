{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU0Tkv5_yMSG"
   },
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdlRpU5syMSJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"C:/Users/user/kym/감성분석Project/대한항공/대한항공_Tone까지(최종분석데이터).csv\").dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1756,
     "status": "error",
     "timestamp": 1564545229837,
     "user": {
      "displayName": "kym kym",
      "photoUrl": "",
      "userId": "09174094218138086178"
     },
     "user_tz": -540
    },
    "id": "dZZ711nPyMSM",
    "outputId": "bfe41c97-5344-405a-fd65-4460a9ada6cb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz_6TXTQyMSP"
   },
   "outputs": [],
   "source": [
    "data=data.sample(frac=1)\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmKx5jeEyMSS"
   },
   "outputs": [],
   "source": [
    "Train_doc = data.loc[:21600]\n",
    "Test_doc = data.loc[21600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BlQfEr1yMSU"
   },
   "outputs": [],
   "source": [
    "Train_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Opn0JQy6yMSY"
   },
   "outputs": [],
   "source": [
    "X_train_doc = Train_doc['Tokens'].str.split(',').values.tolist()\n",
    "y_train_label_doc = Train_doc['Label_3'].values.tolist()\n",
    "\n",
    "X_test_doc = Test_doc['Tokens'].str.split(',').values.tolist()\n",
    "y_test_label_doc = Test_doc['Label_3'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxEUSngOyMSb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train_doc[0:10], sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhWdILPZyMSd"
   },
   "source": [
    "# CNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9TISZHGyMSe"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuN2nTo_yMSh"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 단어에 대한 idx 부여\n",
    "def convert_token_to_idx(token_ls):\n",
    "    for tokens in token_ls:\n",
    "        yield [token2idx[token] for token in tokens]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSgCUJLhyMSj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8oK6zaVyMSm"
   },
   "source": [
    "# 문서 최대 토큰 길이 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJR8ire6yMSn"
   },
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Kh2Bol3yMSq"
   },
   "outputs": [],
   "source": [
    "max_len =[]\n",
    "for i in range(len(X_train_doc)):\n",
    "    max_len.append(len(X_train_doc[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8shOzfJAyMSs"
   },
   "outputs": [],
   "source": [
    "max(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Mpa6SuPyMSv"
   },
   "outputs": [],
   "source": [
    "count_len=Counter(max_len).most_common()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDrE1ijoyMSy"
   },
   "outputs": [],
   "source": [
    "a=count_len.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJNG752MyMS0"
   },
   "outputs": [],
   "source": [
    "count_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNsn_oSDyMS2"
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-Nn2Vd9yMS3"
   },
   "outputs": [],
   "source": [
    "token2idx = defaultdict(lambda : len(token2idx)) # token과 index를 매칭시켜주는 딕셔너리\n",
    "pad = token2idx['<PAD>']  # pytorch Variable로 변환하기 위해, 문장의 길이를 맞춰주기 위한 padding \n",
    "\n",
    "x_train = list(convert_token_to_idx(X_train_doc))\n",
    "x_test = list(convert_token_to_idx(X_test_doc))\n",
    "\n",
    "idx2token = {val : key for key,val in token2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igHS6p8jyMS5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train[0:10], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UFSjULvyMS9"
   },
   "outputs": [],
   "source": [
    "def add_padding(token_ls, max_len):\n",
    "    for i, tokens in enumerate(token_ls):\n",
    "        n_token = len(tokens)\n",
    "        \n",
    "        # 길이가 짧으면 padding을 추가\n",
    "        if n_token < max_len:\n",
    "            token_ls[i] += [pad] * (max_len - n_token) # 부족한 만큼 padding을 추가함\n",
    "        \n",
    "        # 길이가 길면, max_len에서 짜름\n",
    "        elif n_token > max_len:\n",
    "            token_ls[i] = tokens[:max_len]\n",
    "    return token_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoP09Z_RyMTB"
   },
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "x_train = add_padding(x_train, max_len)\n",
    "x_test = add_padding(x_test, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aF_mDBrDyMTE"
   },
   "outputs": [],
   "source": [
    "' '.join([idx2token[x] for x in x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCQa0_ORyMTG"
   },
   "outputs": [],
   "source": [
    "def convert_to_long_variable(w2i_ls):\n",
    "    return Variable(torch.LongTensor(w2i_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mc2rbEiyMTJ"
   },
   "outputs": [],
   "source": [
    "x_train = convert_to_long_variable(x_train)\n",
    "x_test = convert_to_long_variable(x_test)\n",
    "\n",
    "y_train = convert_to_long_variable(y_train_label_doc)\n",
    "y_test = convert_to_long_variable(y_test_label_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-0B-wj5yMTM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5uDWHxryMTQ"
   },
   "outputs": [],
   "source": [
    "class CNN_text(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_words, embed_size, pad_index, hid_size, drop_rate, kernel_size_ls, num_filter, n_class):\n",
    "        super(CNN_text, self).__init__()\n",
    "        \n",
    "        self.pad_index = pad_index              # 단어 embedding 과정에서 제외시킬 padding token\n",
    "        self.embed_size = embed_size            # 임베딩 차원의 크기\n",
    "        self.hid_size = hid_size                # 히든 레이어 갯수\n",
    "        self.drop_rate = drop_rate              # 드롭아웃 비율\n",
    "        self.num_filter = num_filter            # 필터의 갯수 \n",
    "        self.kernel_size_ls = kernel_size_ls    # 각기 다른 필터 사이즈가 담긴 리스트\n",
    "        self.num_kernel = len(kernel_size_ls)   # 필터 사이즈의 종류 수\n",
    "        self.n_class = n_class                  # 카테고리 갯수\n",
    "        \n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=n_words, \n",
    "            embedding_dim=embed_size,\n",
    "            padding_idx=self.pad_index\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # kernel size는 (n-gram, embed_size)이다.\n",
    "        # 커널의 열(column)의 크기는 embed_size와 일치하므로, 단어 임베딩 벡터를 모두 커버한다.\n",
    "        # 따라서, n의 row 크기를 갖는 커널은 한번에 n개의 단어를 커버하는 n-gram 커널이라고 볼 수 있다.\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, num_filter, (kernel_size, embed_size)) for kernel_size in kernel_size_ls])\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(self.num_kernel*num_filter, hid_size), nn.ReLU(), nn.Dropout(drop_rate),\n",
    "            nn.Linear(hid_size, n_class),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x) # batch_size x max_length x embed_size\n",
    "        embed.unsqueeze_(1)       # batch_size, 1, max_length, embed_size : convolution을 위해 4D로 차원을 조절\n",
    "        \n",
    "        # convolution\n",
    "        conved = [conv(embed).squeeze(3) for conv in self.convs] # [batch_size, num_filter, max_length -kernel_size +1]\n",
    "        \n",
    "        # max_pooling\n",
    "        pooled = [F.max_pool1d(conv, (conv.size(2))).squeeze(2) for conv in conved] # [batch_size, num_kernel, num_filter]\n",
    "            \n",
    "        # dropout\n",
    "        dropouted = [F.dropout(pool, self.drop_rate) for pool in pooled]\n",
    "        \n",
    "        # concatenate\n",
    "        concated = torch.cat(dropouted, dim = 1) # [batch_size, num_kernel * num_filter]\n",
    "        logit = self.lin(concated)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DouhZvu_yMTS"
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'n_words' : len(token2idx),        # 고유한 단어 토큰의 갯수\n",
    "    'embed_size' : 30,                # 임베딩 차원의 크기\n",
    "    'pad_index' : token2idx['<PAD>'],  # 패딩 토큰\n",
    "    'hid_size' : 100,                  # 히든 레이어 갯수\n",
    "    'drop_rate' : 0.5,                 # 드롭아웃 비율          (원문에서는 0.5를 사용)\n",
    "    'kernel_size_ls' : [3,4,5],      # 커널 사이즈 리스트        (원문애서는 3,4,5를 사용)\n",
    "    'num_filter' : 32,                 # 각 사이즈 별 커널 갯수 (원문에서는 100을 사용)\n",
    "    'n_class' : 3,                  # 카테고리 갯수\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwYaekq9yMT3"
   },
   "outputs": [],
   "source": [
    "model = CNN_text(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFT6SjEjyMT6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vbDOZO-yMT9"
   },
   "source": [
    "# 모델저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jz-ExdwpyMT9"
   },
   "outputs": [],
   "source": [
    "savePath = \"C:/Users/user/kym/감성분석Project/대한항공/CNN_model.pth\"\n",
    "torch.save(model.state_dict(), savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLg58xBCyMT_",
    "outputId": "410be1c7-16cf-4b52-dd94-6d6f6f2a527f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load\n",
    "new_model = CNN_text(**params)\n",
    "new_model.load_state_dict(torch.load(\"C:/Users/user/kym/감성분석Project/대한항공/CNN_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6D4ibX3MyMUC",
    "outputId": "4941dfc5-74cd-4ab5-f13d-754507d95b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_text(\n",
       "  (embed): Embedding(2007, 30, padding_idx=0)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 30), stride=(1, 1))\n",
       "    (1): Conv2d(1, 32, kernel_size=(4, 30), stride=(1, 1))\n",
       "    (2): Conv2d(1, 32, kernel_size=(5, 30), stride=(1, 1))\n",
       "  )\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=96, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7u-TWJPyMUE",
    "outputId": "1d541ec1-e81d-431d-d7f3-8a753caac463",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(new_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xkpyV8pyMUF"
   },
   "source": [
    "# 모델 Training 및 Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuxjBIZjyMUG",
    "outputId": "de23ed2a-3b71-4dcb-9479-9870bf4a44f4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch : 1,  loss : 34.64312365722656,  accuracy :0.610\n",
      "=================================================================================================\n",
      "Train epoch : 2,  loss : 32.08012243652344,  accuracy :0.602\n",
      "=================================================================================================\n",
      "Train epoch : 3,  loss : 31.980193298339845,  accuracy :0.612\n",
      "=================================================================================================\n",
      "Train epoch : 4,  loss : 31.704383850097656,  accuracy :0.636\n",
      "=================================================================================================\n",
      "Train epoch : 5,  loss : 31.39335986328125,  accuracy :0.624\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr = 0.01\n",
    "batch_size = 500\n",
    "\n",
    "train_idx = np.arange(x_train.size(0))\n",
    "test_idx = np.arange(x_test.size(0))\n",
    "optimizer = torch.optim.Adam(new_model.parameters(),lr) # 원문에서는 Adadelta 알고리즘을 사용\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "loss_ls = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    new_model.train()\n",
    "    \n",
    "    # input 데이터 순서 섞기\n",
    "    random.shuffle(train_idx)\n",
    "    x_train = x_train[train_idx]\n",
    "    y_train = y_train[train_idx]\n",
    "    train_loss = 0\n",
    "\n",
    "    for start_idx, end_idx in zip(range(0, x_train.size(0), batch_size),\n",
    "                                  range(batch_size, x_train.size(0)+1, batch_size)):\n",
    "        \n",
    "        x_batch = x_train[start_idx : end_idx]\n",
    "        y_batch = y_train[start_idx : end_idx].long()\n",
    "        \n",
    "        scores = new_model(x_batch)\n",
    "        predict = F.softmax(scores, dim=1).argmax(dim = 1)\n",
    "        \n",
    "        acc = (predict == y_batch).sum().item() / batch_size\n",
    "        \n",
    "        loss = criterion(scores, y_batch)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Train epoch : %s,  loss : %s,  accuracy :%.3f'%(epoch+1, train_loss / batch_size, acc))\n",
    "    print('=================================================================================================')\n",
    "    \n",
    "    loss_ls.append(train_loss)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        new_model.eval()\n",
    "        scores = new_model(x_test)\n",
    "        predict = F.softmax(scores, dim=1).argmax(dim = 1)\n",
    "        \n",
    "        acc = (predict == y_test.long()).sum().item() / y_test.size(0)\n",
    "        loss = criterion(scores, y_test.long())\n",
    "        \n",
    "        print('*************************************************************************************************')\n",
    "        print('*************************************************************************************************')\n",
    "        print('Test Epoch : %s, Test Loss : %.03f , Test Accuracy : %.03f'%(epoch+1, loss.item()/y_test.size(0), acc))\n",
    "        print('*************************************************************************************************')\n",
    "        print('*************************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQQi0KZ5yMUH"
   },
   "source": [
    "# 특정 기간 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nq4XlOUJyMUI"
   },
   "outputs": [],
   "source": [
    "x_predict_data = X_train_doc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0B32H5yYyMUJ",
    "outputId": "7847a75d-7b06-4d71-f453-d197a79f32dc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-03-10'"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6ObcAALyMUM",
    "outputId": "63b94d5c-11c0-44ba-def1-65003d1cf8b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.asiatoday.co.kr/view.php?key=20170310010006761'"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Url'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJGvMCsVyMUN",
    "outputId": "10b344f5-8c56-4d3f-dae6-4f05e8f521c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사측과의 임금협상을 매듭짓지 못한 대한항공 조종사 노동조합이 두 달여만에 다시 파업에 돌입한다.대항항공 조종사 노조는 일부터 일까지 일간 파업을 벌인다고 일 밝혔다. 대한항공 노사는 이날 오후 시께 년 임금협상과 관련해 차 교섭을 벌였지만 사측이 제시한 수정안을 노조가 수용하지 않으면서 파업이 결정됐다.사측은 년 . 년 총액 대비 .의 임금 인상안을 제시했다. 또 보안수당을 만원에서 만원으로 올려 지난해 월 일부터 적용하겠다는 뜻을 전달했다.노조는 이는 조합이 바라는 변화와는 간극이 너무나 크다며 앞으로도 교섭의 장을 닫지는 않을 것이나 변화를 찾기 위한 행동을 준비할 수밖에 없다고 밝혔다.앞서 노조는 지난해 월 일부터 파업을 벌였다가 임금교섭에 집중하겠다며 일주일 만인 월 일 잠정 중단한 바 있다. 당시 노조는 조종사 인력 유출을 막고 경영진만 수익을 누리는 잘못된 구조를 개선하기 위해 실질 임금 인상이 필요하다고 주장했다.노조는 차 파업에 참여했던 조합원을 제외하고 총 명의 차 파업 참가자를 무작위 선발해 파업을 진행할 계획이다.안소연 기자 ..대한항공 조종사 노조 파업 '"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Content'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFjnHPrTyMUP",
    "outputId": "8491f292-d5c8-461d-cc32-06cc41c8ad91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057657889000000004"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rate'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGpGOFAxyMUR",
    "outputId": "0ba2d84d-0e73-439d-eafa-e9828ccaaecc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.442758654"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AC'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrZXDqCSyMUT",
    "outputId": "cdeb3f30-27ac-4f11-f0b1-1de729e579b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label_3'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixvkd3TNyMUU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 토큰화 된 1개의 문서를 이중리스트로 만듦 \n",
    "x_predict_data_2 = []\n",
    "x_predict_data_2.append(x_predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuKMixgLyMUW",
    "outputId": "6f6b0d65-e31b-4153-bec0-1a22783aea56",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['임금',\n",
       "  '협상',\n",
       "  '못한',\n",
       "  '대한항공',\n",
       "  '조종사',\n",
       "  '노동조합',\n",
       "  '다시',\n",
       "  '파업',\n",
       "  '돌입',\n",
       "  '항공',\n",
       "  '조종사',\n",
       "  '노조',\n",
       "  '일간',\n",
       "  '파업',\n",
       "  '밝혔',\n",
       "  '대한항공',\n",
       "  '노사',\n",
       "  '이날',\n",
       "  '임금',\n",
       "  '협상',\n",
       "  '관련',\n",
       "  '제시',\n",
       "  '노조',\n",
       "  '수용',\n",
       "  '파업',\n",
       "  '결정',\n",
       "  '총액',\n",
       "  '대비',\n",
       "  '임금',\n",
       "  '제시',\n",
       "  '보안',\n",
       "  '지난해',\n",
       "  '적용',\n",
       "  '전달',\n",
       "  '노조',\n",
       "  '변화',\n",
       "  '변화',\n",
       "  '위한',\n",
       "  '행동',\n",
       "  '준비',\n",
       "  '밝혔',\n",
       "  '앞서',\n",
       "  '노조',\n",
       "  '지난해',\n",
       "  '파업',\n",
       "  '임금',\n",
       "  '집중',\n",
       "  '주일',\n",
       "  '중단',\n",
       "  '당시',\n",
       "  '노조',\n",
       "  '조종사',\n",
       "  '인력',\n",
       "  '경영진',\n",
       "  '수익',\n",
       "  '잘못',\n",
       "  '구조',\n",
       "  '개선',\n",
       "  '위해',\n",
       "  '실질',\n",
       "  '임금',\n",
       "  '인상',\n",
       "  '필요',\n",
       "  '주장',\n",
       "  '노조',\n",
       "  '파업',\n",
       "  '참여',\n",
       "  '제외',\n",
       "  '파업',\n",
       "  '선발',\n",
       "  '파업',\n",
       "  '계획',\n",
       "  '안소연',\n",
       "  '대한항공',\n",
       "  '조종사',\n",
       "  '노조',\n",
       "  '파업']]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_predict_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49cQFtNsyMUX"
   },
   "outputs": [],
   "source": [
    "x_test = list(convert_token_to_idx(x_predict_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9AaNUzGyMUb",
    "outputId": "25bf8104-326d-4c65-fc8a-54915e9f8907",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)\n",
    "# 1개의 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvwdF1dWyMUd"
   },
   "outputs": [],
   "source": [
    "x_test = add_padding(x_test, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBuSi4J_yMUf"
   },
   "outputs": [],
   "source": [
    "x_test = convert_to_long_variable(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tK9eGEWyMUh",
    "outputId": "aade0e8b-f28d-428e-e3eb-dcb5b5cff8de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1505, 1506,  816,   25,   47, 1507,   56, 1508, 1509,   27,   47, 1510,\n",
       "          283, 1508,  162,   25, 1511,   95, 1505, 1506,   97, 1237, 1510,  935,\n",
       "         1508,  287, 1233,  772, 1505, 1237, 1064,  109,   60,  120, 1510,  342,\n",
       "          342,  334,  326, 1348,  162,  598, 1510,  109, 1508, 1505,  242, 1512,\n",
       "          920,  921, 1510,   47,    6, 1292,  737, 1327,  125,  741,   40, 1402,\n",
       "         1505,  668,   89, 1098, 1510, 1508,  874,  228, 1508,  259, 1508,  164,\n",
       "         1513,   25,   47, 1510, 1508,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test\n",
    "# 임베딩 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8GZI_ftyMUj"
   },
   "outputs": [],
   "source": [
    "scores = new_model(x_test)\n",
    "predict = F.softmax(scores, dim=1).argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9ot0YM1yMUl",
    "outputId": "dfc2e1ca-c96e-4eb3-b817-e7cf1955f95f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0729, -1.7293,  0.7453]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_L-0kMWyMUm",
    "outputId": "7b358f84-8ad5-40a2-c466-fb3c22cd382c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict\n",
    "# 예측 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97VFCxyxyMUq"
   },
   "outputs": [],
   "source": [
    "predict_ls = predict.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrMzhL17yMUr",
    "outputId": "17e2c333-3c6d-45fa-898a-f0905079b61c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ez-BIoWWyMUt",
    "outputId": "5e38564f-893b-425b-b43d-3f9a7c1a003b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5614, 0.0341, 0.4045]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(scores, dim=1)\n",
    "# 각각 0, 1, 2 값이 나올 확률"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "대한항공_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
